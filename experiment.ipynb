{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b3dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import gzip, csv, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60223889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ROOT = Path(\"Pipeline_watch_data\")\n",
    "LANDING = ROOT / \"landing\"\n",
    "REFERENCE = ROOT / \"reference\"\n",
    "REPORTS = ROOT / \"reports\"\n",
    "BRONZE = ROOT / \"bronze\"\n",
    "QUAR = ROOT / \"quarantine\"\n",
    "REJECTS = ROOT/ \"rejects\"\n",
    "\n",
    "for folder in [REFERENCE, REPORTS, BRONZE, QUAR, REJECTS]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc20cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necssary constants\n",
    "FRESHNESS_HOURS = 100\n",
    "MIN_RECORDS = 1000\n",
    "MAX_ERROR_RATE = 0.02\n",
    "LAT_MAX = 60000\n",
    "BYTES_MAX = 5_000_000\n",
    "MAX_FILE_SIZE_MB = 50\n",
    "REQUIRED_COULUMNS = {\"event_time\",\n",
    "                     \"user_id\",\n",
    "                     \"session_id\",\n",
    "                     \"country\",\n",
    "                     \"page\",\n",
    "                     \"referrer\",\n",
    "                     \"bytes_sent\",\n",
    "                     \"latency_ms\"}\n",
    "UNKNOWN_REF={\"\", \"unknown\", \"n/a\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d7d162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tenantA': 300, 'tenantB': 450, 'tenantC': 400}\n"
     ]
    }
   ],
   "source": [
    "allowed = {}\n",
    "with open(REFERENCE / \"allowed_countries.csv\",\"r\") as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        allowed.setdefault(row['tenant'], set()).add(row['allowed_country'])\n",
    "\n",
    "with open(REFERENCE/ \"baseline_latency.json\", \"r\") as f:\n",
    "    baseline_latency = json.load(f)\n",
    "    print(baseline_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a9ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Pipeline_watch_data\\landing\\tenantA_2025-10-03T16.csv.gz is fresh enough: 4 days, 2:02:07.404433\n",
      "File Pipeline_watch_data\\landing\\tenantA_2025-10-03T17.csv.gz is fresh enough: 4 days, 1:02:07.404433\n",
      "File Pipeline_watch_data\\landing\\tenantA_2025-10-03T18.csv.gz is fresh enough: 4 days, 0:02:07.404433\n",
      "File Pipeline_watch_data\\landing\\tenantB_2025-10-03T17.csv.gz is fresh enough: 4 days, 1:02:07.404433\n",
      "File Pipeline_watch_data\\landing\\tenantB_2025-10-03T18.csv.gz is fresh enough: 4 days, 0:02:07.404433\n",
      "File Pipeline_watch_data\\landing\\tenantC_2025-10-03T17.csv.gz is fresh enough: 4 days, 1:02:07.404433\n",
      "File Pipeline_watch_data\\landing\\tenantC_2025-10-03T18.csv.gz is fresh enough: 4 days, 0:02:07.404433\n"
     ]
    }
   ],
   "source": [
    "# at top\n",
    "now_utc = datetime.now(timezone.utc)\n",
    "files = sorted(LANDING.glob(\"*.csv.gz\"))\n",
    "stage_status = {}\n",
    "\n",
    "for fpath in files:\n",
    "    stem = fpath.name.replace(\".csv.gz\", \"\")\n",
    "    record = {'file_name': fpath.name, 'stage':'file_checks', \"status\": None, \"reason\": None}\n",
    "\n",
    "    try:\n",
    "        # safer split in case tenant has underscores later\n",
    "        tenant, hour_str = stem.split(\"_\", 1)         # e.g. tenantA , 2025-10-03T16\n",
    "\n",
    "        # parse exactly the pattern in filenames\n",
    "        file_hour = datetime.strptime(hour_str, \"%Y-%m-%dT%H\").replace(tzinfo=timezone.utc)\n",
    "\n",
    "        # if you reach here, parsing worked â€” do your normal processing...\n",
    "        record[\"status\"] = \"OK\"\n",
    "        stage_status[fpath.name] = record\n",
    "\n",
    "    except Exception as e:\n",
    "        record[\"status\"] = 'REJECT'\n",
    "        record[\"reason\"] = ['BAD_NAME', str(e)]\n",
    "        stage_status[fpath.name] = record\n",
    "        dest = REJECTS / 'tenants' / 'unknown' / 'date=unknown' / 'hour=unknown'\n",
    "        dest.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(fpath, dest / fpath.name)\n",
    "        continue\n",
    "\n",
    "    #Check if the file size is too large\n",
    "    size_ok = 0 < fpath.stat().st_size < MAX_FILE_SIZE_MB * 1024 * 1024\n",
    "    if fpath.stat().st_size > MAX_FILE_SIZE_MB * 1024 * 1024:\n",
    "           print(f\"File {fpath} is too large: {fpath.stat().st_size / (1024*1024):.2f)} MB\")\n",
    "\n",
    "    fresh_enough = (now_utc - file_hour) <= timedelta(hours=FRESHNESS_HOURS)\n",
    "    if fresh_enough:\n",
    "        print(f\"File {fpath} is fresh enough: {now_utc - file_hour}\")\n",
    "    \n",
    "    if not size_ok or not fresh_enough:\n",
    "        reasons = []\n",
    "        if not size_ok: reasons.append('BAD_SIZE')\n",
    "        if not fresh_enough: reasons.append('STALE')\n",
    "        record.update({'status':'REJECT', 'reason':reasons, 'tenant': tenant, 'file_hour_utc': file_hour.isoformat()})\n",
    "        stage_status[fpath.name] = record\n",
    "        dest = REJECTS / 'tenants' / 'unknown' / 'date=unknown' / 'hour=unknown'\n",
    "        dest.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(fpath, dest / fpath.name) \n",
    "    else:\n",
    "         record.update({'status': 'OK_TO_READ', 'tenant': tenant, 'file_hour_utc': file_hour.isoformat()})\n",
    "         stage_status[fpath] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f957ba32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tenant_-10-03T16.csv.gz': {'file_name': 'tenant_-10-03T16.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'REJECT',\n",
       "  'reason': ['BAD_NAME',\n",
       "   \"time data '-10-03T16' does not match format '%Y-%m-%dT%H'\"]},\n",
       " 'tenantA_2025-10-03T16.csv.gz': {'file_name': 'tenantA_2025-10-03T16.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantA',\n",
       "  'file_hour_utc': '2025-10-03T16:00:00+00:00'},\n",
       " WindowsPath('Pipeline_watch_data/landing/tenantA_2025-10-03T16.csv.gz'): {'file_name': 'tenantA_2025-10-03T16.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantA',\n",
       "  'file_hour_utc': '2025-10-03T16:00:00+00:00'},\n",
       " 'tenantA_2025-10-03T17.csv.gz': {'file_name': 'tenantA_2025-10-03T17.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantA',\n",
       "  'file_hour_utc': '2025-10-03T17:00:00+00:00'},\n",
       " WindowsPath('Pipeline_watch_data/landing/tenantA_2025-10-03T17.csv.gz'): {'file_name': 'tenantA_2025-10-03T17.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantA',\n",
       "  'file_hour_utc': '2025-10-03T17:00:00+00:00'},\n",
       " 'tenantA_2025-10-03T18.csv.gz': {'file_name': 'tenantA_2025-10-03T18.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantA',\n",
       "  'file_hour_utc': '2025-10-03T18:00:00+00:00'},\n",
       " WindowsPath('Pipeline_watch_data/landing/tenantA_2025-10-03T18.csv.gz'): {'file_name': 'tenantA_2025-10-03T18.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantA',\n",
       "  'file_hour_utc': '2025-10-03T18:00:00+00:00'},\n",
       " 'tenantB_2025-10-03T17.csv.gz': {'file_name': 'tenantB_2025-10-03T17.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantB',\n",
       "  'file_hour_utc': '2025-10-03T17:00:00+00:00'},\n",
       " WindowsPath('Pipeline_watch_data/landing/tenantB_2025-10-03T17.csv.gz'): {'file_name': 'tenantB_2025-10-03T17.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantB',\n",
       "  'file_hour_utc': '2025-10-03T17:00:00+00:00'},\n",
       " 'tenantB_2025-10-03T18.csv.gz': {'file_name': 'tenantB_2025-10-03T18.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantB',\n",
       "  'file_hour_utc': '2025-10-03T18:00:00+00:00'},\n",
       " WindowsPath('Pipeline_watch_data/landing/tenantB_2025-10-03T18.csv.gz'): {'file_name': 'tenantB_2025-10-03T18.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantB',\n",
       "  'file_hour_utc': '2025-10-03T18:00:00+00:00'},\n",
       " 'tenantC_2025-10-03T17.csv.gz': {'file_name': 'tenantC_2025-10-03T17.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantC',\n",
       "  'file_hour_utc': '2025-10-03T17:00:00+00:00'},\n",
       " WindowsPath('Pipeline_watch_data/landing/tenantC_2025-10-03T17.csv.gz'): {'file_name': 'tenantC_2025-10-03T17.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantC',\n",
       "  'file_hour_utc': '2025-10-03T17:00:00+00:00'},\n",
       " 'tenantC_2025-10-03T18.csv.gz': {'file_name': 'tenantC_2025-10-03T18.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantC',\n",
       "  'file_hour_utc': '2025-10-03T18:00:00+00:00'},\n",
       " WindowsPath('Pipeline_watch_data/landing/tenantC_2025-10-03T18.csv.gz'): {'file_name': 'tenantC_2025-10-03T18.csv.gz',\n",
       "  'stage': 'file_checks',\n",
       "  'status': 'OK_TO_READ',\n",
       "  'reason': None,\n",
       "  'tenant': 'tenantC',\n",
       "  'file_hour_utc': '2025-10-03T18:00:00+00:00'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e74fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File tenantA_2025-10-03T16.csv.gz passed schema check for tenant tenantA at hour 2025-10-03 16:00:00+00:00\n",
      "âš ï¸ Missing file: Pipeline_watch_data\\landing\\Pipeline_watch_data\\landing\\tenantA_2025-10-03T16.csv.gz\n",
      "âœ… File tenantA_2025-10-03T17.csv.gz passed schema check for tenant tenantA at hour 2025-10-03 17:00:00+00:00\n",
      "âš ï¸ Missing file: Pipeline_watch_data\\landing\\Pipeline_watch_data\\landing\\tenantA_2025-10-03T17.csv.gz\n",
      "âœ… File tenantA_2025-10-03T18.csv.gz passed schema check for tenant tenantA at hour 2025-10-03 18:00:00+00:00\n",
      "âš ï¸ Missing file: Pipeline_watch_data\\landing\\Pipeline_watch_data\\landing\\tenantA_2025-10-03T18.csv.gz\n",
      "âœ… File tenantB_2025-10-03T17.csv.gz passed schema check for tenant tenantB at hour 2025-10-03 17:00:00+00:00\n",
      "âš ï¸ Missing file: Pipeline_watch_data\\landing\\Pipeline_watch_data\\landing\\tenantB_2025-10-03T17.csv.gz\n",
      "âœ… File tenantB_2025-10-03T18.csv.gz passed schema check for tenant tenantB at hour 2025-10-03 18:00:00+00:00\n",
      "âš ï¸ Missing file: Pipeline_watch_data\\landing\\Pipeline_watch_data\\landing\\tenantB_2025-10-03T18.csv.gz\n",
      "âœ… File tenantC_2025-10-03T17.csv.gz passed schema check for tenant tenantC at hour 2025-10-03 17:00:00+00:00\n",
      "âš ï¸ Missing file: Pipeline_watch_data\\landing\\Pipeline_watch_data\\landing\\tenantC_2025-10-03T17.csv.gz\n",
      "âœ… File tenantC_2025-10-03T18.csv.gz passed schema check for tenant tenantC at hour 2025-10-03 18:00:00+00:00\n",
      "âš ï¸ Missing file: Pipeline_watch_data\\landing\\Pipeline_watch_data\\landing\\tenantC_2025-10-03T18.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# Schema validation\n",
    "for fname, record in stage_status.items():  # fname is string like 'tenantA_2025-10-03T16.csv.gz'\n",
    "    if record['status'] != 'OK_TO_READ':\n",
    "        continue\n",
    "\n",
    "    tenant = record['tenant']\n",
    "    file_hour = datetime.fromisoformat(record['file_hour_utc'])\n",
    "\n",
    "    file_path = LANDING / fname   # âœ… join folder + filename\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(f\"âš ï¸ Missing file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    with gzip.open(file_path, 'rt', newline='', encoding='utf-8') as gz:\n",
    "        reader = csv.DictReader(gz)\n",
    "        cols = set(reader.fieldnames or [])\n",
    "        if not REQUIRED_COULUMNS.issubset(cols):\n",
    "            missing = REQUIRED_COULUMNS - cols\n",
    "            record.update({'status': 'REJECT', 'reason': ['MISSING_COLUMNS', *missing]})\n",
    "            dest = (\n",
    "                REJECTS / 'tenants' / tenant /\n",
    "                f\"date={file_hour.date()}\" /\n",
    "                f\"hour={file_hour.hour:02d}\"\n",
    "            )\n",
    "            dest.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(file_path, dest / file_path.name)\n",
    "            print(f\"ðŸš« File {fname} is missing columns: {missing}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"âœ… File {fname} passed schema check for tenant {tenant} at hour {file_hour}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82d4544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2da780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
